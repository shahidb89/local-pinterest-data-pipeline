{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9de0ab1f-4d6a-4d00-833b-7dceb0ebb7bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pin = spark.read.csv(\"/FileStore/tables/pin_data.csv\", \n",
    "                        header=True, \n",
    "                        inferSchema=True, \n",
    "                        sep=\",\")\n",
    "\n",
    "df_geo = spark.read.csv(\"/FileStore/tables/geo_data.csv\", \n",
    "                        header=True, \n",
    "                        inferSchema=True, \n",
    "                        sep=\",\")\n",
    "\n",
    "df_user = spark.read.csv(\"/FileStore/tables/user_data.csv\", \n",
    "                        header=True, \n",
    "                        inferSchema=True, \n",
    "                        sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b52bf643-fce4-4fd6-a0ce-f9fd15e33748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>poster_name</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>is_image_or_video</th>\n",
       "      <th>image_src</th>\n",
       "      <th>save_location</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4097</td>\n",
       "      <td>bf1bf0af-01ee-469c-9709-acc562a64fbf</td>\n",
       "      <td>How to Easily Homeschool Consistently</td>\n",
       "      <td>How can you homeschool consistently when it's ...</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>Classically Homeschooling | Education at the K...</td>\n",
       "      <td>How To Start Homeschooling,Homeschooling Resou...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/20/33/85/203385...</td>\n",
       "      <td>/data/education</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8204</td>\n",
       "      <td>8d2c3ddb-144d-4e2c-8824-d73484834973</td>\n",
       "      <td>You Will Never Understand The Damage You Did T...</td>\n",
       "      <td>You will never understand the damage you did t...</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>Andrea Groneman</td>\n",
       "      <td>Letting Go Quotes,Go For It Quotes,Hurt Quotes...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/9e/7c/b2/9e7cb2...</td>\n",
       "      <td>/data/quotes</td>\n",
       "      <td>quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>cab8a53e-40e1-4324-9e25-9b339ade9fd2</td>\n",
       "      <td>Romantic Travel Destinations For Adventurous C...</td>\n",
       "      <td>Romantic travel destinations shouldn't be limi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOCIETY19</td>\n",
       "      <td>Places To Travel,Travel Destinations,Places To...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/37/82/eb/3782eb...</td>\n",
       "      <td>/data/travel</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6156</td>\n",
       "      <td>02b1529c-2fd3-47a8-af1e-e48e936df09c</td>\n",
       "      <td>1867 Italianate Villa In Manchester New Hampsh...</td>\n",
       "      <td>CLICK HERE 1867 Italianate Villa In Manchester...</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Captivating Houses | Old Houses &amp; Home decor</td>\n",
       "      <td>Home Decor Kitchen,Rustic Kitchen,Interior Des...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/80/f7/eb/80f7eb...</td>\n",
       "      <td>/data/home-decor</td>\n",
       "      <td>home-decor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10256</td>\n",
       "      <td>13a1a2ad-a1e4-4bca-8e70-41cb4ca4530c</td>\n",
       "      <td>Portugal Travel Guide: An Epic 10 Day Itinerar...</td>\n",
       "      <td>Use this 10-day Portugal itinerary to help you...</td>\n",
       "      <td>617.0</td>\n",
       "      <td>Travel + Food Blogger ➳ TeriakiTalks</td>\n",
       "      <td>Visit Portugal,Spain And Portugal,Lisbon Portu...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/85/e6/03/85e603...</td>\n",
       "      <td>/data/travel</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4116</td>\n",
       "      <td>efcd3e17-5d87-4610-9470-c7c4e2707ce3</td>\n",
       "      <td>Teach Genetics With Edible DNA - The Happy Hou...</td>\n",
       "      <td>My kids would be thrilled to learn about genet...</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>Toni Herrbach (Happy Housewife)</td>\n",
       "      <td>Kid Science,Food Science Experiments,Science P...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/fb/a1/28/fba128...</td>\n",
       "      <td>/data/education</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2069</td>\n",
       "      <td>4b494dc9-7c21-4f43-ac9e-8bb64488ea83</td>\n",
       "      <td>10 of the Best Red Christmas Tree Ideas - Back...</td>\n",
       "      <td>The color of passion is also the color of Chri...</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>Backyard Boss</td>\n",
       "      <td>Red And Gold Christmas Tree,Elegant Christmas ...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/e1/d2/93/e1d293...</td>\n",
       "      <td>/data/christmas</td>\n",
       "      <td>christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>1e39f505-1561-440e-a76e-1b84ea3df078</td>\n",
       "      <td>How to Draw a Realistic Face Step By Step | Po...</td>\n",
       "      <td>Most people believe that drawing a realistic f...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Pouted Lifestyle Magazine</td>\n",
       "      <td>Realistic Pencil Drawings,Pencil Drawing Tutor...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/89/4a/a7/894aa7...</td>\n",
       "      <td>/data/art</td>\n",
       "      <td>art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8222</td>\n",
       "      <td>f4902a59-1708-4fa1-8916-141f19b0225d</td>\n",
       "      <td>A Religious Person Will Do What He Is Told</td>\n",
       "      <td>Religious | God | Jesus | Quotes | Inspiration...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Minds Journal</td>\n",
       "      <td>Quotable Quotes,Wisdom Quotes,Book Quotes,Word...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/e3/cd/3b/e3cd3b...</td>\n",
       "      <td>/data/quotes</td>\n",
       "      <td>quotes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8226</td>\n",
       "      <td>443624b9-8320-4a4b-ac4d-0761307790d9</td>\n",
       "      <td>100 Inspirational Quotes to Make You Feel Bett...</td>\n",
       "      <td>Words of wisdom for all of life's crazy moments.</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>REDBOOK Magazine</td>\n",
       "      <td>Quotes Thoughts,Life Quotes Love,Inspiring Quo...</td>\n",
       "      <td>image</td>\n",
       "      <td>https://i.pinimg.com/originals/8b/40/66/8b4066...</td>\n",
       "      <td>/data/quotes</td>\n",
       "      <td>quotes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ind</th>\n      <th>unique_id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>follower_count</th>\n      <th>poster_name</th>\n      <th>tag_list</th>\n      <th>is_image_or_video</th>\n      <th>image_src</th>\n      <th>save_location</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4097</td>\n      <td>bf1bf0af-01ee-469c-9709-acc562a64fbf</td>\n      <td>How to Easily Homeschool Consistently</td>\n      <td>How can you homeschool consistently when it's ...</td>\n      <td>13000.0</td>\n      <td>Classically Homeschooling | Education at the K...</td>\n      <td>How To Start Homeschooling,Homeschooling Resou...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/20/33/85/203385...</td>\n      <td>/data/education</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8204</td>\n      <td>8d2c3ddb-144d-4e2c-8824-d73484834973</td>\n      <td>You Will Never Understand The Damage You Did T...</td>\n      <td>You will never understand the damage you did t...</td>\n      <td>6000.0</td>\n      <td>Andrea Groneman</td>\n      <td>Letting Go Quotes,Go For It Quotes,Hurt Quotes...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/9e/7c/b2/9e7cb2...</td>\n      <td>/data/quotes</td>\n      <td>quotes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10253</td>\n      <td>cab8a53e-40e1-4324-9e25-9b339ade9fd2</td>\n      <td>Romantic Travel Destinations For Adventurous C...</td>\n      <td>Romantic travel destinations shouldn't be limi...</td>\n      <td>NaN</td>\n      <td>SOCIETY19</td>\n      <td>Places To Travel,Travel Destinations,Places To...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/37/82/eb/3782eb...</td>\n      <td>/data/travel</td>\n      <td>travel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6156</td>\n      <td>02b1529c-2fd3-47a8-af1e-e48e936df09c</td>\n      <td>1867 Italianate Villa In Manchester New Hampsh...</td>\n      <td>CLICK HERE 1867 Italianate Villa In Manchester...</td>\n      <td>40000.0</td>\n      <td>Captivating Houses | Old Houses &amp; Home decor</td>\n      <td>Home Decor Kitchen,Rustic Kitchen,Interior Des...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/80/f7/eb/80f7eb...</td>\n      <td>/data/home-decor</td>\n      <td>home-decor</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10256</td>\n      <td>13a1a2ad-a1e4-4bca-8e70-41cb4ca4530c</td>\n      <td>Portugal Travel Guide: An Epic 10 Day Itinerar...</td>\n      <td>Use this 10-day Portugal itinerary to help you...</td>\n      <td>617.0</td>\n      <td>Travel + Food Blogger ➳ TeriakiTalks</td>\n      <td>Visit Portugal,Spain And Portugal,Lisbon Portu...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/85/e6/03/85e603...</td>\n      <td>/data/travel</td>\n      <td>travel</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4116</td>\n      <td>efcd3e17-5d87-4610-9470-c7c4e2707ce3</td>\n      <td>Teach Genetics With Edible DNA - The Happy Hou...</td>\n      <td>My kids would be thrilled to learn about genet...</td>\n      <td>68000.0</td>\n      <td>Toni Herrbach (Happy Housewife)</td>\n      <td>Kid Science,Food Science Experiments,Science P...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/fb/a1/28/fba128...</td>\n      <td>/data/education</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2069</td>\n      <td>4b494dc9-7c21-4f43-ac9e-8bb64488ea83</td>\n      <td>10 of the Best Red Christmas Tree Ideas - Back...</td>\n      <td>The color of passion is also the color of Chri...</td>\n      <td>76000.0</td>\n      <td>Backyard Boss</td>\n      <td>Red And Gold Christmas Tree,Elegant Christmas ...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/e1/d2/93/e1d293...</td>\n      <td>/data/christmas</td>\n      <td>christmas</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30</td>\n      <td>1e39f505-1561-440e-a76e-1b84ea3df078</td>\n      <td>How to Draw a Realistic Face Step By Step | Po...</td>\n      <td>Most people believe that drawing a realistic f...</td>\n      <td>65000.0</td>\n      <td>Pouted Lifestyle Magazine</td>\n      <td>Realistic Pencil Drawings,Pencil Drawing Tutor...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/89/4a/a7/894aa7...</td>\n      <td>/data/art</td>\n      <td>art</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8222</td>\n      <td>f4902a59-1708-4fa1-8916-141f19b0225d</td>\n      <td>A Religious Person Will Do What He Is Told</td>\n      <td>Religious | God | Jesus | Quotes | Inspiration...</td>\n      <td>NaN</td>\n      <td>The Minds Journal</td>\n      <td>Quotable Quotes,Wisdom Quotes,Book Quotes,Word...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/e3/cd/3b/e3cd3b...</td>\n      <td>/data/quotes</td>\n      <td>quotes</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8226</td>\n      <td>443624b9-8320-4a4b-ac4d-0761307790d9</td>\n      <td>100 Inspirational Quotes to Make You Feel Bett...</td>\n      <td>Words of wisdom for all of life's crazy moments.</td>\n      <td>133000.0</td>\n      <td>REDBOOK Magazine</td>\n      <td>Quotes Thoughts,Life Quotes Love,Inspiring Quo...</td>\n      <td>image</td>\n      <td>https://i.pinimg.com/originals/8b/40/66/8b4066...</td>\n      <td>/data/quotes</td>\n      <td>quotes</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, when, col\n",
    "#df_pin cleaning\n",
    "\n",
    "##1 Replace empty entries and entries with no relevant data in each column with \n",
    "\n",
    "\n",
    "# List of placeholders to treat as null\n",
    "null_like_values = [\"\", \"N/A\", \"n/a\", \"na\", \"NaN\", \"None\", \"null\"]\n",
    "\n",
    "# Replace in all columns\n",
    "for c in df_pin.columns:\n",
    "    df_pin_cleaned = df_pin.withColumn(c, when(col(c).isin(null_like_values), None).otherwise(col(c)))\n",
    "\n",
    "##2 Perform the necessary transformations on the follower_count to ensure every entry is a number. Make sure the data type of this column is an int\n",
    "# Step 1: Clean commas and ensure lowercase string type\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \",\", \"\"))\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\"follower_count\", col(\"follower_count\").cast(\"string\"))\n",
    "\n",
    "# Step 2: Convert 'k' and 'm' to numeric values\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\n",
    "    \"follower_count\",\n",
    "    when(col(\"follower_count\").rlike(\"^[0-9.]+k$\"), \n",
    "         (regexp_replace(\"follower_count\", \"k\", \"\").cast(\"float\") * 1000).cast(\"int\"))\n",
    "    .when(col(\"follower_count\").rlike(\"^[0-9.]+m$\"), \n",
    "          (regexp_replace(\"follower_count\", \"m\", \"\").cast(\"float\") * 1000000).cast(\"int\"))\n",
    "    .otherwise(col(\"follower_count\").cast(\"int\"))\n",
    ")\n",
    "\n",
    "##3 Ensure that each column containing numeric data has a numeric data type\n",
    "\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\"idx\", col(\"idx\").cast(\"integer\")) \\\n",
    "         .withColumn(\"downloaded\", col(\"downloaded\").cast(\"int\"))\n",
    "\n",
    "##4 Clean the data in the save_location column to include only the save location path\n",
    "df_pin_cleaned = df_pin_cleaned.withColumn(\"save_location\", \n",
    "    regexp_replace(col(\"save_location\"), \"^(Local save in )\", \"\"))\n",
    "\n",
    "##5 Rename the index column to ind\n",
    "df_pin_cleaned = df_pin_cleaned.withColumnRenamed(\"idx\", \"ind\")\n",
    "\n",
    "##6 Reorder the DataFrame columns\n",
    "new_column_order_pin = [\n",
    "    \"ind\", \n",
    "    \"unique_id\", \n",
    "    \"title\", \n",
    "    \"description\", \n",
    "    \"follower_count\", \n",
    "    \"poster_name\", \n",
    "    \"tag_list\", \n",
    "    \"is_image_or_video\", \n",
    "    \"image_src\", \n",
    "    \"save_location\", \n",
    "    \"category\"\n",
    "]\n",
    "\n",
    "df_pin_cleaned = df_pin_cleaned.select(new_column_order_pin)\n",
    "# Show result\n",
    "df_pin_cleaned.limit(10).toPandas()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30b18a89-c32c-48d5-b12d-278afb49acbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>country</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4097</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>[1.28495, 74.2608]</td>\n",
       "      <td>2020-01-09 11:55:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8204</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>[-18.1973, -126.543]</td>\n",
       "      <td>2019-05-28 05:38:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>[-89.3669, -170.886]</td>\n",
       "      <td>2018-03-07 12:37:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6156</td>\n",
       "      <td>Norway</td>\n",
       "      <td>[-9.45376, -77.97]</td>\n",
       "      <td>2018-07-23 00:14:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10256</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>[17.7952, -44.441]</td>\n",
       "      <td>2020-09-21 22:31:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4116</td>\n",
       "      <td>Saint Pierre and Miquelon</td>\n",
       "      <td>[-7.80883, 19.4768]</td>\n",
       "      <td>2017-12-15 07:59:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2069</td>\n",
       "      <td>Chile</td>\n",
       "      <td>[-59.0335, -161.59]</td>\n",
       "      <td>2018-09-21 01:14:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>Saint Barthelemy</td>\n",
       "      <td>[61.9983, 65.5766]</td>\n",
       "      <td>2022-07-07 18:43:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8222</td>\n",
       "      <td>Albania</td>\n",
       "      <td>[-87.2, -177.109]</td>\n",
       "      <td>2022-05-07 18:07:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8226</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>[-83.9199, -162.946]</td>\n",
       "      <td>2019-11-03 16:00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ind</th>\n      <th>country</th>\n      <th>coordinates</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4097</td>\n      <td>Denmark</td>\n      <td>[1.28495, 74.2608]</td>\n      <td>2020-01-09 11:55:49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8204</td>\n      <td>Maldives</td>\n      <td>[-18.1973, -126.543]</td>\n      <td>2019-05-28 05:38:33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10253</td>\n      <td>Azerbaijan</td>\n      <td>[-89.3669, -170.886]</td>\n      <td>2018-03-07 12:37:25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6156</td>\n      <td>Norway</td>\n      <td>[-9.45376, -77.97]</td>\n      <td>2018-07-23 00:14:40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10256</td>\n      <td>Azerbaijan</td>\n      <td>[17.7952, -44.441]</td>\n      <td>2020-09-21 22:31:19</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4116</td>\n      <td>Saint Pierre and Miquelon</td>\n      <td>[-7.80883, 19.4768]</td>\n      <td>2017-12-15 07:59:58</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2069</td>\n      <td>Chile</td>\n      <td>[-59.0335, -161.59]</td>\n      <td>2018-09-21 01:14:59</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30</td>\n      <td>Saint Barthelemy</td>\n      <td>[61.9983, 65.5766]</td>\n      <td>2022-07-07 18:43:40</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8222</td>\n      <td>Albania</td>\n      <td>[-87.2, -177.109]</td>\n      <td>2022-05-07 18:07:02</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8226</td>\n      <td>Bahrain</td>\n      <td>[-83.9199, -162.946]</td>\n      <td>2019-11-03 16:00:21</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import array, col\n",
    "#df_geo cleaning\n",
    "\n",
    "##Create a new column coordinates that contains an array based on the latitude and longitude columns\n",
    "df_geo_cleaned = df_geo.withColumn(\"coordinates\", array(\"latitude\", \"longitude\"))\n",
    "\n",
    "##Drop the latitude and longitude columns from the DataFrame\n",
    "df_geo_cleaned = df_geo_cleaned.drop(\"latitude\", \"longitude\")\n",
    "\n",
    "##Convert the timestamp column from a string to a timestamp data type\n",
    "df_geo_cleaned = df_geo_cleaned.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "\n",
    "##Reorder the DataFrame columns \n",
    "df_geo_cleaned = df_geo_cleaned.withColumnRenamed(\"idx\", \"ind\")\n",
    "\n",
    "new_column_order_geo = [\"ind\",\n",
    "                    \"country\",\n",
    "                    \"coordinates\",\n",
    "                    \"timestamp\"\n",
    "]\n",
    "\n",
    "df_geo_cleaned = df_geo_cleaned.select(new_column_order_geo)\n",
    "df_geo_cleaned.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a6d244-1b40-456a-85f3-39af55bdc257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>user_name</th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4097</td>\n",
       "      <td>Kristen Lyons</td>\n",
       "      <td>21</td>\n",
       "      <td>2016-03-24 02:42:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8204</td>\n",
       "      <td>David Davis</td>\n",
       "      <td>38</td>\n",
       "      <td>2016-11-20 06:55:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>Aaron Anderson</td>\n",
       "      <td>21</td>\n",
       "      <td>2015-10-23 04:43:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6156</td>\n",
       "      <td>Christopher Alvarez</td>\n",
       "      <td>28</td>\n",
       "      <td>2016-10-26 20:31:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10256</td>\n",
       "      <td>Amber Morris</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-03-02 09:47:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4116</td>\n",
       "      <td>Jason Luna</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-06-11 02:08:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2069</td>\n",
       "      <td>Alexandra Lawrence</td>\n",
       "      <td>34</td>\n",
       "      <td>2016-04-12 09:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>Jeffery Richardson</td>\n",
       "      <td>43</td>\n",
       "      <td>2016-07-22 03:44:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8222</td>\n",
       "      <td>Aaron Anderson</td>\n",
       "      <td>21</td>\n",
       "      <td>2015-10-24 06:35:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8226</td>\n",
       "      <td>Austin Alvarez</td>\n",
       "      <td>38</td>\n",
       "      <td>2015-11-27 20:15:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ind</th>\n      <th>user_name</th>\n      <th>age</th>\n      <th>date_joined</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4097</td>\n      <td>Kristen Lyons</td>\n      <td>21</td>\n      <td>2016-03-24 02:42:31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8204</td>\n      <td>David Davis</td>\n      <td>38</td>\n      <td>2016-11-20 06:55:49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10253</td>\n      <td>Aaron Anderson</td>\n      <td>21</td>\n      <td>2015-10-23 04:43:54</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6156</td>\n      <td>Christopher Alvarez</td>\n      <td>28</td>\n      <td>2016-10-26 20:31:58</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10256</td>\n      <td>Amber Morris</td>\n      <td>24</td>\n      <td>2016-03-02 09:47:07</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4116</td>\n      <td>Jason Luna</td>\n      <td>23</td>\n      <td>2017-06-11 02:08:47</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2069</td>\n      <td>Alexandra Lawrence</td>\n      <td>34</td>\n      <td>2016-04-12 09:18:00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30</td>\n      <td>Jeffery Richardson</td>\n      <td>43</td>\n      <td>2016-07-22 03:44:24</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8222</td>\n      <td>Aaron Anderson</td>\n      <td>21</td>\n      <td>2015-10-24 06:35:27</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>8226</td>\n      <td>Austin Alvarez</td>\n      <td>38</td>\n      <td>2015-11-27 20:15:05</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat, lit, col\n",
    "#df_user cleaning\n",
    "\n",
    "##Create a new column user_name that concatenates the information found in the first_name and last_name columns\n",
    "df_user_cleaned = df_user.withColumn(\"user_name\", concat(col(\"first_name\"), lit(\" \"), col(\"last_name\")))\n",
    "\n",
    "##Drop the first_name and last_name columns from the DataFrame\n",
    "df_user_cleaned = df_user_cleaned.drop(\"first_name\", \"last_name\")\n",
    "df_user.limit(10).toPandas()\n",
    "\n",
    "##Convert the date_joined column from a string to a timestamp data type\n",
    "df_user_cleaned = df_user_cleaned.withColumn(\"date_joined\", col(\"date_joined\").cast(\"timestamp\"))\n",
    "\n",
    "##Reorder the DataFrame columns\n",
    "df_user_cleaned = df_user_cleaned.withColumnRenamed(\"idx\", \"ind\")\n",
    "\n",
    "new_column_order_user = [\"ind\",\n",
    "                         \"user_name\",\n",
    "                         \"age\",\n",
    "                         \"date_joined\"\n",
    "]  \n",
    "\n",
    "df_user_cleaned = df_user_cleaned.select(new_column_order_user)\n",
    "df_user_cleaned.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db60689a-103b-42a9-b5bc-a29b9b880f5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+--------------+--------------+\n|country                                     |category      |category_count|\n+--------------------------------------------+--------------+--------------+\n|Algeria                                     |quotes        |11            |\n|Albania                                     |art           |8             |\n|Afghanistan                                 |finance       |7             |\n|Aruba                                       |art           |6             |\n|Andorra                                     |tattoos       |4             |\n|Azerbaijan                                  |finance       |4             |\n|Antarctica (the territory South of 60 deg S)|tattoos       |3             |\n|Belgium                                     |christmas     |3             |\n|Brazil                                      |home-decor    |3             |\n|American Samoa                              |beauty        |2             |\n|Angola                                      |diy-and-crafts|2             |\n|Anguilla                                    |education     |2             |\n|Antigua and Barbuda                         |home-decor    |2             |\n|Armenia                                     |vehicles      |2             |\n|Bahamas                                     |art           |2             |\n|Bangladesh                                  |home-decor    |2             |\n|Barbados                                    |art           |2             |\n|Belarus                                     |travel        |2             |\n|Benin                                       |beauty        |2             |\n|Bermuda                                     |tattoos       |2             |\n+--------------------------------------------+--------------+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "##Find the most popular category in each country\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Step 1: Join on 'ind'\n",
    "df_joined = df_pin_cleaned.join(df_geo_cleaned, on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Step 2: Group by country and category, count posts\n",
    "df_grouped = df_joined.groupBy(\"country\", \"category\").agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Step 3: Use window function to get the top category per country\n",
    "from pyspark.sql.functions import row_number\n",
    "window_spec = Window.partitionBy(\"country\").orderBy(df_grouped[\"category_count\"].desc())\n",
    "\n",
    "df_result = df_grouped.withColumn(\"row_num\", row_number().over(window_spec)) \\\n",
    "                      .filter(\"row_num = 1\") \\\n",
    "                      .select(\"country\", \"category\", \"category_count\")\n",
    "\n",
    "# Show result\n",
    "df_result.orderBy(\n",
    "    [\"category_count\", \"country\"], \n",
    "    ascending=[False, True]  # False=DESC, True=ASC\n",
    ").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c2bc48b-465a-44e2-8298-39e2dc67acfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+--------------+\n|post_year|category        |category_count|\n+---------+----------------+--------------+\n|2018     | Value Twin Pack|1             |\n|2018     |art             |8             |\n|2018     |beauty          |7             |\n|2018     |christmas       |12            |\n|2018     |diy-and-crafts  |8             |\n|2018     |education       |6             |\n|2018     |event-planning  |10            |\n|2018     |finance         |8             |\n|2018     |home-decor      |8             |\n|2018     |mens-fashion    |8             |\n|2018     |quotes          |5             |\n|2018     |tattoos         |9             |\n|2018     |travel          |12            |\n|2018     |vehicles        |8             |\n|2019     |1               |2             |\n|2019     |2k              |1             |\n|2019     |art             |10            |\n|2019     |beauty          |4             |\n|2019     |christmas       |14            |\n|2019     |diy-and-crafts  |8             |\n+---------+----------------+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "##Find how many posts each category had between 2018 and 2022.\n",
    "\n",
    "from pyspark.sql.functions import year, col, count\n",
    "\n",
    "# Step 1: Join pin data with geo data to get timestamp\n",
    "df_joined = df_pin_cleaned.join(df_geo_cleaned, on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Step 2: Extract year from timestamp\n",
    "df_with_year = df_joined.withColumn(\"post_year\", year(col(\"timestamp\")))\n",
    "\n",
    "# Step 3: Filter for years 2018 to 2022\n",
    "df_filtered = df_with_year.filter((col(\"post_year\") >= 2018) & (col(\"post_year\") <= 2022))\n",
    "\n",
    "# Step 4: Group by year and category, and count\n",
    "df_result = df_filtered.groupBy(\"post_year\", \"category\") \\\n",
    "                       .agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Show the result\n",
    "df_result.orderBy(\"post_year\", \"category\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae30b831-b8fe-4fd9-897d-24036fcd9d19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+\n|             country|         poster_name|follower_count|\n+--------------------+--------------------+--------------+\n|             Algeria|           YourTango|        942000|\n|            Mongolia|               ZAFUL|        893000|\n|             Armenia|Michelle {CraftyM...|        892000|\n|              Brazil|              Lively|        892000|\n|               Aruba|         GQ Magazine|        874000|\n|Central African R...|             PureWow|        868000|\n|           Argentina|         Next Luxury|        800000|\n|             Andorra|           Glaminati|        799000|\n|            Anguilla|           dresslily|        760000|\n|         Afghanistan|        TheUnstitchd|        723000|\n|           Swaziland|          Casa Vogue|        685000|\n|          Bangladesh|  Smart School House|        673000|\n|             Burundi|        Studio McGee|        662000|\n|               Gabon|               SHAPE|        637000|\n|               Korea|         Decor Fácil|        616000|\n|               Haiti|No Time For Flash...|        610000|\n|            Djibouti|    The Dating Divas|        577000|\n|Antarctica (the t...|            HikenDip|        501000|\n|             Albania|       WeAreTeachers|        500000|\n|          Madagascar|          Big Cartel|        472000|\n+--------------------+--------------------+--------------+\nonly showing top 20 rows\n\n+-------+--------------+\n|country|follower_count|\n+-------+--------------+\n|Algeria|        942000|\n+-------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Step 1: For each country find the user with the most followers.\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Join on 'ind' to access country + followers + poster_name\n",
    "df_joined = df_pin_cleaned.join(df_geo_cleaned, on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Define window partitioned by country, ordered by follower_count desc\n",
    "window_spec = Window.partitionBy(\"country\").orderBy(col(\"follower_count\").desc())\n",
    "\n",
    "# Add row number to pick top poster per country\n",
    "df_top_per_country = df_joined.select(\"country\", \"poster_name\", \"follower_count\") \\\n",
    "                              .withColumn(\"row_num\", row_number().over(window_spec)) \\\n",
    "                              .filter(\"row_num = 1\") \\\n",
    "                              .select(\"country\", \"poster_name\", \"follower_count\")\n",
    "\n",
    "# Show Results\n",
    "df_top_per_country.orderBy(\"follower_count\", ascending=False).show()\n",
    "\n",
    "# Step 2: Based on the above query, find the country with the user with most followers.\n",
    "\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "# Find the max follower count globally\n",
    "max_followers = df_top_per_country.agg(max(\"follower_count\").alias(\"max_follower_count\"))\n",
    "\n",
    "# Join back to filter the country that has this max\n",
    "df_country_with_max_user = df_top_per_country.join(\n",
    "    max_followers,\n",
    "    df_top_per_country.follower_count == max_followers.max_follower_count,\n",
    "    how=\"inner\"\n",
    ").select(\"country\", \"follower_count\")\n",
    "\n",
    "df_country_with_max_user.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c5bc440-b400-476b-8ce6-af01554c97f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------------+\n|age_group|category    |category_count|\n+---------+------------+--------------+\n|18-24    |quotes      |27            |\n|25-35    |christmas   |20            |\n|36-50    |travel      |14            |\n|50+      |mens-fashion|7             |\n+---------+------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# What is the most popular category people post to based on the following age groups:\n",
    "\n",
    "# 18-24\n",
    "# 25-35\n",
    "# 36-50\n",
    "# +50\n",
    "\n",
    "from pyspark.sql.functions import when, col, count\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Step 1: Join pins with users to get access to age\n",
    "df_joined = df_pin_cleaned.join(df_user_cleaned, on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Step 2: Create age_group column\n",
    "df_with_age_group = df_joined.withColumn(\n",
    "    \"age_group\",\n",
    "    when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "    .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "    .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "    .when(col(\"age\") > 50, \"50+\")\n",
    ")\n",
    "\n",
    "# Step 3: Group by age_group and category, count posts\n",
    "df_grouped = df_with_age_group.groupBy(\"age_group\", \"category\") \\\n",
    "                              .agg(count(\"*\").alias(\"category_count\"))\n",
    "\n",
    "# Step 4: Get most popular category per age group using window\n",
    "window_spec = Window.partitionBy(\"age_group\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "df_result = df_grouped.withColumn(\"row_num\", row_number().over(window_spec)) \\\n",
    "                      .filter(\"row_num = 1\") \\\n",
    "                      .select(\"age_group\", \"category\", \"category_count\")\n",
    "\n",
    "# Show the final result\n",
    "df_result.show(truncate=False)\n",
    "\n",
    "# row_count = df_user_cleaned.count()\n",
    "# print(f\"\\nNumber of rows: {row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465f6643-d121-4f30-b99c-f1a34d67c003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+\n|age_group|median_follower_count|\n+---------+---------------------+\n|18-24    |50000                |\n|25-35    |19000                |\n|36-50    |7000                 |\n|50+      |5000                 |\n+---------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#What is the median follower count for users in the following age groups:\n",
    "\n",
    "# 18-24\n",
    "# 25-35\n",
    "# 36-50\n",
    "# 50+\n",
    "\n",
    "from pyspark.sql.functions import when, col, expr\n",
    "\n",
    "# Step 1: Join pin and user data\n",
    "df_joined = df_pin_cleaned.join(df_user_cleaned, on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Step 2: Create age_group column\n",
    "df_with_age_group = df_joined.withColumn(\n",
    "    \"age_group\",\n",
    "    when((col(\"age\") >= 18) & (col(\"age\") <= 24), \"18-24\")\n",
    "    .when((col(\"age\") >= 25) & (col(\"age\") <= 35), \"25-35\")\n",
    "    .when((col(\"age\") >= 36) & (col(\"age\") <= 50), \"36-50\")\n",
    "    .when(col(\"age\") > 50, \"50+\")\n",
    ")\n",
    "\n",
    "# Step 3: Use approx_percentile to get median follower count per age group\n",
    "df_median = df_with_age_group.groupBy(\"age_group\") \\\n",
    "    .agg(expr(\"approx_percentile(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "# Show the result\n",
    "df_median.orderBy('age_group').show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9fd533b-117e-4014-9f03-e9ffa14b8571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n|post_year|number_users_joined|\n+---------+-------------------+\n|2015     |183                |\n|2016     |238                |\n|2017     |79                 |\n+---------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find how many users have joined between 2015 and 2020.\n",
    "\n",
    "from pyspark.sql.functions import year, col, count\n",
    "\n",
    "# Step 1: Extract year from date_joined\n",
    "df_with_year = df_user_cleaned.withColumn(\"post_year\", year(col(\"date_joined\")))\n",
    "\n",
    "# Step 2: Filter for years 2015 to 2020\n",
    "df_filtered = df_with_year.filter((col(\"post_year\") >= 2015) & (col(\"post_year\") <= 2020))\n",
    "\n",
    "# Step 3: Group by year and count users\n",
    "df_result = df_filtered.groupBy(\"post_year\") \\\n",
    "                       .agg(count(\"*\").alias(\"number_users_joined\"))\n",
    "\n",
    "# Show the result\n",
    "df_result.orderBy(\"post_year\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a2046ac-64b7-4bc8-91a9-8d4a74bc0a79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+\n|post_year|median_follower_count|\n+---------+---------------------+\n|2015     |79000                |\n|2016     |15000                |\n|2017     |4000                 |\n+---------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find the median follower count of users have joined between 2015 and 2020.\n",
    "\n",
    "from pyspark.sql.functions import year, col, expr\n",
    "\n",
    "# Step 1: Join pins with users to get follower count and date joined\n",
    "df_joined = df_pin_cleaned.join(df_user_cleaned, on=\"ind\", how=\"inner\")\n",
    "\n",
    "# Step 2: Extract year from date_joined\n",
    "df_with_year = df_joined.withColumn(\"post_year\", year(col(\"date_joined\")))\n",
    "\n",
    "# Step 3: Filter for years 2015 to 2020\n",
    "df_filtered = df_with_year.filter((col(\"post_year\") >= 2015) & (col(\"post_year\") <= 2020))\n",
    "\n",
    "# Step 4: Group by post_year and get median follower count\n",
    "df_median = df_filtered.groupBy(\"post_year\") \\\n",
    "    .agg(expr(\"approx_percentile(follower_count, 0.5)\").alias(\"median_follower_count\"))\n",
    "\n",
    "# Show the result\n",
    "df_median.orderBy(\"post_year\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "pinterest_pipeline",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}